# 2020.01.08 水

## Ontology
- [온톨로지(존재론)로 인공지능의 기초를 다진다.](http://ith.kr/chair/semanticweb/sw0302.html)
  - category, metaphor, subject와 같은 많은 용어를 개념화시키고 정의
  - In computer, 컴퓨터에서 사용하는 각종 개념에 대한 설명 또는 정의
  - 현재 컴퓨터 분야의 인공지능과 인공지능 프로그램은 '근대적 의미론의 창시자'로 부르는 독일 철학자 고트롭 프레게(Gottlob Prege, 1848~1925)가 개발한 술어 논리(predicate logic) 체계에 크게 의지
  - 이 후, 알란 튜링(Alan Turing, 1912-1954)과 존 맥카시(John McCarthy, 1927-)에 의해 계승된 인공지능은 지속적인 연구로 시맨틱웹 개발의 핵심으로 떠오름
  - Shared Conceptualization by Thomas R. Gruber
  - 온톨로지는 낱말에 대한 정의와 개념을 명확하게 해주는 학문
  - 개념의 Generalization과 같은 느낌이랄까
  - Taxonomy, inference rule로 object의 class를 정의, 다른 클래스와의 relationship을 정의
  - Globally vs Locally
- ["제발 인공지능 과장하지 마세요"](https://byline.network/2017/05/26-4/)
  - "온톨로지니 뭐니 하는 어려운 이론만 가지고 고객들을 현혹시키지 맙시다. 중요한 건 오직 정답률뿐 입니다. 인공지능 기술도 결국 고객에게 실제로 얼마나 도움이 되느냐가 가장 중요한 것입니다."
  - 와이즈넛 강용성 대표 (영업을 좀 못한다던.._)
  - 인공지능 기술도 기업의 효율성을 약간이라도 제고하기 위한 하나의 도구
  - 고객관계관리(CRM) 시스템의 일례
- [Ontology Learning](http://jens-lehmann.org/files/2014/pol_introduction.pdf)
  - Ontologies in computer science are usually regarded as formal representations of knowldege - often restricted to a particular domain.
  - 관점에 따라, 온톨로지는 taxonomies, thesauri, or richly axiomatized top-level formalisations이 될 수 있다.
    - [어휘집(Vocabulary), Taxonomy, 시소러스, 온톨로지, 메타모델(meta-model)의 차이는 무엇인가?](http://www.ezmeta.co.kr/page/?p=31)
      - ref: What are the differences between a vocabulary, a taxonomy, a thesaurus, an ontology, and a meta-model?
      - Controlled Vocabulary: 분명하게 열거된 용어의 리스트
        - 단지 사람들이 사용하기로 동의하고 그 의미가 이미 이해된 용어들의 set일 수 있다.
      - Taxonomy: 계층적 구조로 조직화된 통제 어휘집 용어의 collection
        - 계층적 연결고리의 의미가 무엇이건 간에 이 연결고리에 의해 명세된 추가적인 의미를 갖고 있다.
      - Thesaurus: 통제 어휘집 용어들의 네트워크화된 collection
        - 2가지 종류의 연결고리를 가진다. 두 용어 사이에 어떤 관계가 있다는 것만 표현한다.
      - Ontology: 온톨로지 표현 언어로 표현된 통제 어휘집
        - 앞서 언급한 모든 것을 지칭한다.
      - meta-model: 관심 도메인 내의 특정 모델들을 구축하기 위해 필요한 구문(constructs)과 규칙(rules)을 분명하게 명시한 모델
    - semantic web 기술
  - [머신러닝(Machine Learning):데이터가 아닌 지식을 학습한다? 딥클로닝 vs 딥러닝](https://steemit.com/kr-newbie/@jenna.pulse9/machine-learning-vs)
    - 머신러닝의 주요 목적은 컴퓨터가 인간의 두뇌와 같은 인지기술을 수행하도록 하고, 인간의 두뇌가 어떻게 학습하는지를 모방하는 것
    - 인간이 학습을 할 때는 '지식'을 기반으로 한다.
    - Knowledge Representation, Ontology 작성의 어려움으로 많이 발전하지 못함
    - semantic net, logicalo-linguistic modeling과 같은 KR 방법은 정적이면서 주어진 지식을 사용하는 R&D의 오랜 역사를 가지고 있지만 '학습'의 맥락에서는 그렇지 않다.
    - 온톨로지(지식 기반) 학습이 어렵지만 대용량 데이터(Corpus) 트레이닝을 일단 이뤄내면 독립성을 유지할 수 있다는 이점이라는 부분과 '일반화'를 시켜버리는 것이 아니냐라는 이유에 대해서 어떻게 대처할 것인지가 상충하고 있다.
    - Deep Cloning vs Deep Learning
    - 텍스트를 읽은 후 자연 언어를 처리하고 지식으로 전환될 때, 딥 클로닝 네트워크는 서로 다른 목적과 다양한 뉴런 기능을 가진 계층으로 구성
    - 이와는 대조적으로 딥러닝은 주시된 학습 모드에서 산출물의 오류를 최소화하기 위해 설계된 뉴런의 동질 구조
    - 딥러닝의 변동성에도 불구하고 어떠한 언어적 활동에도 뉴런 활동이 지정되지 않음
    - 딥 클로닝에서 KR은 지식의 text만 사용하는 원샷 프로세스를 처리할 수 있지만, 딥러닝에선 딥 클로닝에서 필요로 하는 것보다 훨씬 긴 코퍼스 방법 트레이닝 사이클을 필요로 함
    - 뭐, 결국 허우대는 좋지만 사람들이 사용하지 않고 언급하지 않는 것에는 이유가 있는 법.

## [솔트룩스, 내달 딥러닝 세미나... 3세대 AI '뉴로 심볼릭' 소개](http://www.inews24.com/view/1224248)
- 이경일 솔트룩스 대표
- AI 언어모델 버트 기반 자연언어 처리
- 딥러닝 기반 지식 학습과 심층 질의응답
- 융합 신경망을 활용한 대화 분석과 담화 이해
- 딥러닝 기반 음성합성 기술
- 딥러닝 기반 독해기계 MRC 발전 기술 전망
- 이미지, 얼굴인식 의미 구분 등 딥러닝 연구결과를 발표
  
## [Graph Neural Network](http://www.secmem.org/blog/2019/08/17/gnn/)

## [인공지능, 언어 인식 지능의 발전: 인간처럼 '듣고 이해하는' 기계의 등장](https://blog.lgcns.com/1569), 17년 11월 기사
- 언어 인식 분야의 지능이 빠르게 발전되지 못한 것은 기존 사람(전문가) 중심 방법론의 한계 때문
- 기계가 인간의 언어를 인식하기 위해서는 개별 단어의 의미를 이해하는 것을 시작으로, 구문/문장 등 매우 복잡하고 다양한 단어들의 관계를 정확하고 정교하게 모델링해야 함
- 과거에는 이러한 단어 간 관계 정의를 언어학을 전공한 전문가가 중심이 되어 모델링.
- Ontology라 불리는 이러한 언어 모델은 전문가가 일일이 단어 간의 관계를 설정해 놓는 방식으로 구현
- 전문가의 능력, 경험, 투자 비용 등이 언어 인식의 핵심 역량으로 작용
- 새로운 언어가 추가될 때마다 사람이 직접 모델을 다시 수정해야 하거나, 의학/법률/금융 등과 같이 정확한 언어 이해가 필요한 특정한 분야의 전문지식이 바탕이 되어야 하는 경우, 각 분야의 전문가가 언어 모델의 작성에 개입해야 하는 등의 한계가 존재
- 최근 딥러닝이 적용되며 과거와 달리 사람(전문가)에 의존하지 않고 데이터에 기반을 둔 인공지능이 스스로 학습해 언어를 이해하게 하는 방식으로 전환
- 구글은 웹 서비스를 하며 축적된 데이터를 기반으로 'word2vec'이라는 언어 모델을 구현, 수년간 뉴스 서비스를 통해 확보한 텍스트 정보에서 약 1,000억 개에 이르는 단어를 기계 학습에 적용
- 개별 단어가 아닌 구문 단위로 이해된 각각의 단어를 수백 개의 차원으로 구성된 벡터 공간에 위치.
- 구글의 word2vec, 스탠퍼드대의 GloVe 등이 존재, 공개된 Word Embedding을 통해 누구나 쉽게 이들 모델을 기반으로 언어 인식 지능을 구현할 수 있다.
- 데이터를 기반으로 구성된 언어 모델은 과거 온톨로지 방식보다 확장석이 높고 특정 분야에 종속되지 않음\
- Google은 언어 인식, 이해 분야에 딥러닝 기술을 적용한 지 2년 만에 인식 가능 언어를 32개('17.3)까지 확장
- MS, Baidu 또한 매우 다양한 언어에 대해 인간 수준(Human-level)의 언어 이해 지능을 구현해 내고 있다.
- 특히, 바이두의 경우 딥러닝 기반의 언어 인식 기술인 'Deep Speech'논문을 '14, '15년 차례로 발표하며 인간의 개입을 최소화하면서도 높은 성능을 갖는 음성 인식 기술을 구현
- 인간 수준의 언어 인식/이해 지능을 갖게 된 인공지능은 인간의 목소리를 자유롭게 생성해 내기도 함
- 인간의 음성을 학습하여 개별 단어 단위의 발음, 악센트(Accent)뿐만 아니라 문장 단위에서의 억양(Intonation)까지 매우 정교한 수준으로 구현
- DeepMind는 기존 최고 수준이었던 구글의 음성 생성(TTS: Text-to-Speech) 기술을 획기적으로 발전시킨 WaveNet 논문을 발표
- 기존 구글의 방식도 딥러닝에 기반해 구현되었지만, 딥마인드는 알고리즘 고도화와 학습 데이터의 다양화를 통해 성능 향상을 이룸
- 약 100여 개의 문장에 대해 인간의 목소리와 비슷한 정도를 정량화해 테스트한 결과에서 딥마인드가 발표한 WaveNet은 인간 수준인 4.55점에 근사한 4.21점을 기록
- Baidu 정말 만만치 않은 기업.
- DeepVoice라 불리는 이 기술은 특정 사람의 목소리를 반복 학습해, 그 사람의 목소리의 특징을 완벽히 분석, 모델링
- 국내 네이버도 유명 연예인의 목소리를 학습하고 특징을 모델링해 가상으로 생성된 음성으로 동화책을 읽어 주는 서비스를 선보이기도 함 (DEVIEW)
