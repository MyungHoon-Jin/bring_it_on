# [머신러닝 아키텍처가 가야할 길](https://techrecipe.co.kr/posts/2675)
- Google AI 부문을 맡고 있는 Jeff Dean은 18년 1월 튜링상 수상자인 데이비드 패터슨과 공동으로 논문 발표
- 머신러닝 전문가와 컴퓨터 아키텍트가 머신러닝의 잠재력을 실현하기 위해 필요한 컴퓨팅 시스템을 공동 설계하도록 권장
- 18년 7월 베이징에서 열린 칭화-구글 AI 심포지엄에서 연구자가 학습시키고 싶다고 생각하는 모델 트렌드에 대해 언급
- arXiv에 올라온 머신러닝 논문 관련 건수 증가 추이가 1975년 이미 무어의 법칙 상승 곡선을 초과했다고 지적
- 구글이 개발한 머신러닝을 위한 프로세서인 TPU(Tensor Processing Unit) 첫 세대인 TPI v1과 2세대 TPU v2를 예로 하드웨어 설계를 분석
- 2년간의 설계와 3년간 도입 기간으로 도합 5년이라는 시간축에 따라 상황을 파악할 필요가 있다고 밝힘.
- 머신러닝 하드웨어 설계 6가지
  1. Training
      - 생산 단계(추론/예측) + 개발 단계(강화/학습)
      - TFRC(TensorFlow Research Cloud) 프로그램
  2. Batch Size
      - 일괄 처리 크기
  3. Sparsity
      - 신경망이 가진 뉴런 중 일부만 반응하는 것
      - 0과 작은 값을 생략, 머신러닝의 복잡성을 줄일 수 있음
      - Google Brain의 MoE(Mixed of Expert) 같은 경우 이전 방식보다 적은 수로 더 정밀도가 높은 학습이 가능
      - 영어에서 불어 번역 데이터셋 MoE 모델은 기존 1/6 수준 학습만 해도 구글 번역에 쓰이는 GNMT(Google Neural Machine Translation) 모델보다 1.01배 높은 결과를 보임
  4. Quantization
      - Effective cost machine learning inference
      - 이미 훈련된 AI 입출력을 그대로 새로운 AI에 학습시키는 것도 효율을 높이는 데 소홀히 할 수 없는 것
  5. Soft Memory Network
      - 일부 딥러닝 기술은 메모리 엑세스와 비슷한 기능을 제공할 수 있다고 주장
      - Attention Machanism은 데이터 처리를 할 때 긴 sequence 사이 소스 중 선택한 부분에 주의를 지시해 머신러닝 학습 성능을 개선하기 위해 활용
      - 기존 하드 메모리와 달리 소프트 메모리는 정보량이 많은 콘텐츠 선택을 위해 준비된 모든 항목에 대해 가중 평균을 계산
  6. L2L(Learning to Learn)
      - 학습한 것으로부터 학습하는 것
      - 대규모 머신러닝 아키텍처 모델 디자인은 대부분 여전히 인간 전문가가 보유한 경험칙과 직관에 의존
      - AutoML :)
      - Google Brain은 Reinforcement Learning을 이용
